{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import Sequential as Seq, Linear as Lin, Conv2d\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:07:44.560923Z","iopub.execute_input":"2023-07-17T09:07:44.561255Z","iopub.status.idle":"2023-07-17T09:07:49.430680Z","shell.execute_reply.started":"2023-07-17T09:07:44.561224Z","shell.execute_reply":"2023-07-17T09:07:49.429579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_pure = '/kaggle/input/breast-256/gcn_256/Train_gcn/*'\nval_pure =  '/kaggle/input/breast-256/gcn_256/Val_gcn/*'","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:07:49.432494Z","iopub.execute_input":"2023-07-17T09:07:49.433089Z","iopub.status.idle":"2023-07-17T09:07:49.442953Z","shell.execute_reply.started":"2023-07-17T09:07:49.433054Z","shell.execute_reply":"2023-07-17T09:07:49.441979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\ntrain_files = glob.glob(train_pure)\nval_files = glob.glob(val_pure)\nlen(train_files)#6229","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:07:49.445903Z","iopub.execute_input":"2023-07-17T09:07:49.446351Z","iopub.status.idle":"2023-07-17T09:07:49.810685Z","shell.execute_reply.started":"2023-07-17T09:07:49.446311Z","shell.execute_reply":"2023-07-17T09:07:49.809213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install barbar\n!pip install swin-transformer-pytorch","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:07:49.813848Z","iopub.execute_input":"2023-07-17T09:07:49.815142Z","iopub.status.idle":"2023-07-17T09:08:16.657689Z","shell.execute_reply.started":"2023-07-17T09:07:49.815096Z","shell.execute_reply":"2023-07-17T09:08:16.656172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision import transforms\n#import matplotlib.pyplot as plt\nimport torch\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.models as models\nfrom PIL import Image\nimport albumentations\nimport albumentations.pytorch \nimport cv2\nimport torch.nn as nn\nimport copy\nfrom barbar import Bar\nimport io\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:08:16.659953Z","iopub.execute_input":"2023-07-17T09:08:16.660376Z","iopub.status.idle":"2023-07-17T09:08:18.695761Z","shell.execute_reply.started":"2023-07-17T09:08:16.660329Z","shell.execute_reply":"2023-07-17T09:08:18.694588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:08:18.697345Z","iopub.execute_input":"2023-07-17T09:08:18.698045Z","iopub.status.idle":"2023-07-17T09:08:18.738272Z","shell.execute_reply.started":"2023-07-17T09:08:18.698002Z","shell.execute_reply":"2023-07-17T09:08:18.736774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.device_count()","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:08:18.740010Z","iopub.execute_input":"2023-07-17T09:08:18.740716Z","iopub.status.idle":"2023-07-17T09:08:18.764325Z","shell.execute_reply.started":"2023-07-17T09:08:18.740681Z","shell.execute_reply":"2023-07-17T09:08:18.763270Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    torch.cuda.manual_seed(42)\n    torch.cuda.manual_seed_all(42)\n    torch.backends.cudnn.benchmark=True\n    torch.backends.cudnn.deterministic=False  ","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:08:18.765631Z","iopub.execute_input":"2023-07-17T09:08:18.766068Z","iopub.status.idle":"2023-07-17T09:08:18.775042Z","shell.execute_reply.started":"2023-07-17T09:08:18.766036Z","shell.execute_reply":"2023-07-17T09:08:18.774010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class My_data(Dataset):\n    def __init__(self, data, transforms=None):\n        self.image_list = data\n        self.data_len = len(self.image_list)\n        self.transforms = transforms\n        self.eicls = [\"A\", \"F\", \"TA\", \"PT\", \"DC\", \"LC\", \"MC\", \"PC\"]\n        \n    def __getitem__(self, index):\n        current_image_path = self.image_list[index]\n        im_as_im = cv2.imread(current_image_path)\n        im_as_im = cv2.cvtColor(im_as_im, cv2.COLOR_BGR2RGB)\n\n        # Perform label encoding for multi-label classification\n        parts = current_image_path.split('_')[-1].split('-')\n        if parts[2]==\"13412\":\n            labels =[0,0,0,0,1,1,0,0]\n        else:\n            labels = [int(label == parts[0]) for label in self.eicls]       \n        labels = torch.tensor(labels)\n\n        if self.transforms is not None:\n            augmented = self.transforms(image=im_as_im)\n            im_as_im = augmented['image']\n\n        return (im_as_im, labels)\n\n    def __len__(self):\n        return self.data_len","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:08:18.776585Z","iopub.execute_input":"2023-07-17T09:08:18.777024Z","iopub.status.idle":"2023-07-17T09:08:18.788642Z","shell.execute_reply.started":"2023-07-17T09:08:18.776987Z","shell.execute_reply":"2023-07-17T09:08:18.787501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = {\n    'train': albumentations.Compose([\n    albumentations.Resize(256, 256),     \n    albumentations.OneOf([\n                          albumentations.HorizontalFlip(),\n                          albumentations.Rotate(limit=45),\n                          albumentations.VerticalFlip(),\n                          albumentations.GaussianBlur(),\n                          albumentations.NoOp()\n    ], p=1),\n    albumentations.Normalize(mean=(0.787, 0.625, 0.765),\n                       std=(0.105, 0.138, 0.089), p=1),\n    albumentations.pytorch.transforms.ToTensorV2()]),\n    \n    'valid': albumentations.Compose([\n    albumentations.Resize(256, 256),     \n    albumentations.Normalize(mean=(0.786, 0.623, 0.766),\n                       std=(0.105, 0.138, 0.089), p=1),\n    albumentations.pytorch.transforms.ToTensorV2()]),\n    \n}","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:08:18.794135Z","iopub.execute_input":"2023-07-17T09:08:18.794479Z","iopub.status.idle":"2023-07-17T09:08:18.805755Z","shell.execute_reply.started":"2023-07-17T09:08:18.794439Z","shell.execute_reply":"2023-07-17T09:08:18.804513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=My_data(train_files,transforms=transform['train'])\nvalid=My_data(val_files,transforms=transform['valid'])","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:08:18.807241Z","iopub.execute_input":"2023-07-17T09:08:18.808230Z","iopub.status.idle":"2023-07-17T09:08:18.817517Z","shell.execute_reply.started":"2023-07-17T09:08:18.808190Z","shell.execute_reply":"2023-07-17T09:08:18.816454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"a=torch.tensor([0,0,0,0,0,0,0,0])\nfor _,label in train:\n    a=a+label\nprint(a)     \n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:57:42.848166Z","iopub.execute_input":"2023-06-22T10:57:42.850799Z","iopub.status.idle":"2023-06-22T10:58:27.482342Z","shell.execute_reply.started":"2023-06-22T10:57:42.850774Z","shell.execute_reply":"2023-06-22T10:58:27.481311Z"}}},{"cell_type":"code","source":"import torch\n\nclass_samples = [367, 803, 456, 370, 2763, 492, 629, 449]  # Number of samples in each class\ntotal_samples = sum(class_samples)\nsamples=total_samples/len(class_samples)\nclass_weights = [samples / (s + 1e-8) for s in class_samples]\nclass_weights = torch.tensor(class_weights)\nprint(class_weights)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:08:18.819288Z","iopub.execute_input":"2023-07-17T09:08:18.820011Z","iopub.status.idle":"2023-07-17T09:08:18.913970Z","shell.execute_reply.started":"2023-07-17T09:08:18.819975Z","shell.execute_reply":"2023-07-17T09:08:18.912882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(valid)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:08:18.915779Z","iopub.execute_input":"2023-07-17T09:08:18.916147Z","iopub.status.idle":"2023-07-17T09:08:18.922765Z","shell.execute_reply.started":"2023-07-17T09:08:18.916113Z","shell.execute_reply":"2023-07-17T09:08:18.921802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataloader = torch.utils.data.DataLoader(dataset=train, batch_size=16,shuffle=True,num_workers=2,\n                                              pin_memory=True,prefetch_factor=2)\nvalid_dataloader=  torch.utils.data.DataLoader(dataset=valid,batch_size=16,shuffle=False,num_workers=2,\n                                               pin_memory=True ,prefetch_factor=2)  ","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:08:18.924437Z","iopub.execute_input":"2023-07-17T09:08:18.925128Z","iopub.status.idle":"2023-07-17T09:08:18.933801Z","shell.execute_reply.started":"2023-07-17T09:08:18.925078Z","shell.execute_reply":"2023-07-17T09:08:18.932751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in valid_dataloader:\n    print(i)\n    break    ","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:08:18.935389Z","iopub.execute_input":"2023-07-17T09:08:18.936111Z","iopub.status.idle":"2023-07-17T09:08:23.334905Z","shell.execute_reply.started":"2023-07-17T09:08:18.936065Z","shell.execute_reply":"2023-07-17T09:08:23.333709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pip install timm","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:08:23.336805Z","iopub.execute_input":"2023-07-17T09:08:23.341630Z","iopub.status.idle":"2023-07-17T09:08:23.347041Z","shell.execute_reply.started":"2023-07-17T09:08:23.341584Z","shell.execute_reply":"2023-07-17T09:08:23.345982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader\nimport timm\nfrom timm.models import create_model\nfrom timm.data import create_transform\nfrom sklearn.metrics import accuracy_score\n\n# Define device\n# Define Swin Transformer v2 model\n\"\"\"model_name = 'swin_base_patch4_window7_224'\nnum_classes = 8\nmodel = create_model(\n    model_name=model_name,\n    pretrained=True,\n    num_classes=num_classes,\n    drop_rate=0.5,\n    drop_path_rate=0.2,\n    checkpoint_path=None\n)\"\"\"\nmodel = timm.create_model(\n    'swinv2_tiny_window8_256.ms_in1k',\n    pretrained=True,\n    features_only=False,\n    num_classes = 8,\n    drop_path_rate=0.2,\n    drop_rate=0.5\n)\n\n\n\"\"\"for param in model.head.parameters():\n    param.requires_grad = True\nfor param in model.norm.parameters():\n    param.requires_grad = True  \"\"\" \n#model=model.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:08:23.348769Z","iopub.execute_input":"2023-07-17T09:08:23.349470Z","iopub.status.idle":"2023-07-17T09:08:27.023522Z","shell.execute_reply.started":"2023-07-17T09:08:23.349437Z","shell.execute_reply":"2023-07-17T09:08:27.022361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:08:27.025043Z","iopub.execute_input":"2023-07-17T09:08:27.026028Z","iopub.status.idle":"2023-07-17T09:08:27.030946Z","shell.execute_reply.started":"2023-07-17T09:08:27.025990Z","shell.execute_reply":"2023-07-17T09:08:27.029925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"import torch\n\n\n# Iterate over the parameters and check requires_grad\nfor name, param in model.named_parameters():\n    if param.requires_grad:\n        print(f\"Parameter '{name}' requires grad.\")\n    else:\n        print(f\"Parameter '{name}' does not require grad.\")\n","metadata":{}},{"cell_type":"markdown","source":"import torch\nimport torch.nn as nn\n\nclass FocalLossWithClassWeights(nn.Module):\n    def __init__(self, class_weights, alpha=1, gamma=2):\n        super(FocalLossWithClassWeights, self).__init__()\n        self.class_weights = class_weights\n        self.alpha = alpha\n        self.gamma = gamma\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, input, target):\n        class_weights = self.class_weights.to(target.device)\n        weighted_logits = class_weights * input\n        probs = self.sigmoid(weighted_logits)\n\n        loss = -(self.alpha * torch.pow(1 - probs, self.gamma) * target * torch.log(probs + 1e-8)\n                 + (1 - target) * torch.log(1 - probs + 1e-8))\n\n        return loss.mean()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T09:33:20.843661Z","iopub.execute_input":"2023-06-22T09:33:20.844418Z","iopub.status.idle":"2023-06-22T09:33:20.853144Z","shell.execute_reply.started":"2023-06-22T09:33:20.844383Z","shell.execute_reply":"2023-06-22T09:33:20.852281Z"}}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=2.0, class_weights=None):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.class_weights = class_weights\n\n    def forward(self, logits, labels):\n        probs = torch.sigmoid(logits)\n        ce_loss = nn.BCELoss()(probs, labels)\n        weight = (1 - probs).pow(self.gamma)\n        loss = ce_loss  # Initialize loss with cross-entropy loss\n        if self.class_weights is not None:\n            weight = weight * self.class_weights\n            loss = loss * weight\n        return loss\n","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:08:27.032641Z","iopub.execute_input":"2023-07-17T09:08:27.033355Z","iopub.status.idle":"2023-07-17T09:08:27.046148Z","shell.execute_reply.started":"2023-07-17T09:08:27.033318Z","shell.execute_reply":"2023-07-17T09:08:27.045062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"for param in model.parameters():\n    param.requires_grad =True\n    #print(param.requires_grad)\n","metadata":{}},{"cell_type":"code","source":"from torch.optim.lr_scheduler import ReduceLROnPlateau\n#model = nn.DataParallel(model, device_ids = [0, 1])\nmodel = model.to(device)\nclass_weights=class_weights.to(device)\n#criterion = torch.nn.BCEWithLogitsLoss(weight=class_weights_normalized)\n#criterion = FocalLossWithClassWeights(class_weights)\ncriterion = FocalLoss(class_weights)\noptimizer = optim.AdamW(\n    filter(lambda p: p.requires_grad, model.parameters()), \n    lr=1e-4)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.5)\nbest_model_wts = model.state_dict()\nbest_optimizer_state =optimizer.state_dict()\nbest_acc = 0.0","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:08:27.047610Z","iopub.execute_input":"2023-07-17T09:08:27.048249Z","iopub.status.idle":"2023-07-17T09:08:27.112078Z","shell.execute_reply.started":"2023-07-17T09:08:27.048211Z","shell.execute_reply":"2023-07-17T09:08:27.111004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit(model, dataloader, optimizer,scheduler, criterion):\n    #print('Training')\n    model.train()\n    train_running_loss = 0.0\n    train_running_correct = 0\n    accum_iter = 4  \n    \n    for i, (inputs, labels) in enumerate(Bar(dataloader)):\n            inputs = inputs.to(device)           \n            labels = labels.float().to(device)\n            optimizer.zero_grad()\n            #model.zero_grad(set_to_none=True)\n            # Forward pass - compute outputs on input data using the model\n            outputs = model(inputs)\n            thresholds = [0.5, 0.5, 0.5,0.5,0.5,0.5,0.5,0.5]\n            # Compute loss\n            loss = criterion(outputs, labels)\n            train_running_loss += loss.item()* inputs.size(0)\n           # _ , preds = torch.max(outputs.data, 1)\n            # Apply sigmoid activation to obtain probabilities\n            #preds = (outputs > 0.5).float()\n            probs = torch.sigmoid(outputs)\n            preds = torch.zeros_like(probs)\n            \n            # Set predicted labels based on the threshold\n            for i, threshold in enumerate(thresholds):\n                preds[:, i] = (probs[:, i] >= threshold).float()\n            train_running_correct += (preds == labels).all(dim=1).float().sum()\n            # Backpropagate the gradients\n            loss /= accum_iter\n            loss.backward() \n            \n                       \n            if ((i + 1) % accum_iter == 0) :\n                optimizer.step()\n                optimizer.zero_grad()\n                    \n            \n    scheduler.step()\n            \n    train_loss = train_running_loss/len(dataloader.dataset)\n    train_accuracy = 100. * train_running_correct/len(dataloader.dataset)    \n    return train_loss, train_accuracy","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:08:27.113718Z","iopub.execute_input":"2023-07-17T09:08:27.114111Z","iopub.status.idle":"2023-07-17T09:08:27.125610Z","shell.execute_reply.started":"2023-07-17T09:08:27.114074Z","shell.execute_reply":"2023-07-17T09:08:27.124143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validate(model, dataloader, optimizer, criterion):\n    #print('Validating')\n    model.eval()\n    val_running_loss = 0.0\n    val_running_correct = 0\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(dataloader):\n            inputs = inputs.to(device)\n            labels = labels.float()\n            labels = labels.to(device)\n            outputs = model(inputs)\n            thresholds = [0.5, 0.5, 0.5,0.5,0.5,0.5,0.5,0.5]\n            loss = criterion(outputs, labels)\n            \n            val_running_loss += loss.item()*inputs.size(0)\n            #_, preds = torch.max(outputs.data, 1)\n            #preds = (outputs > 0.5).float()\n            probs = torch.sigmoid(outputs)\n            preds = torch.zeros_like(probs)\n            # Set predicted labels based on the threshold\n            for i, threshold in enumerate(thresholds):\n                preds[:, i] = (probs[:, i] >= threshold).float()\n            val_running_correct += (preds == labels).all(dim=1).float().sum()\n        \n    val_loss = val_running_loss/len(dataloader.dataset)\n    val_accuracy = 100. * val_running_correct/len(dataloader.dataset)        \n    return val_loss, val_accuracy","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:08:27.127430Z","iopub.execute_input":"2023-07-17T09:08:27.128103Z","iopub.status.idle":"2023-07-17T09:08:27.141780Z","shell.execute_reply.started":"2023-07-17T09:08:27.128067Z","shell.execute_reply":"2023-07-17T09:08:27.140728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"import time as time\nhistory=[]\nbest_model_wts = copy.deepcopy(model.state_dict())\n#best_optimizer_state = copy.deepcopy(optimizer.state_dict())\nbest_acc = 0.0\nepochs=50\n\nfor epoch in range(epochs):\n    epoch_start = time.time()\n    print('Epoch-{0}/{1} lr: {2}'.format(epoch+1,epochs ,optimizer.param_groups[0]['lr']))\n    if  epoch > 14:\n        for param in model.parameters():\n            param.requires_grad =True            \n    #print(f\"Epoch {epoch+1} of {epochs}\")\n    train_epoch_loss, train_epoch_accuracy = fit(model,train_dataloader,optimizer,scheduler,criterion)\n    val_epoch_loss, val_epoch_accuracy = validate(model,valid_dataloader,optimizer,criterion)\n    \n    epoch_end = time.time()\n    history.append([epoch+1,train_epoch_loss, train_epoch_accuracy, val_epoch_loss, val_epoch_accuracy,(epoch_end-epoch_start)])\n    print(f\"Train Loss: {train_epoch_loss:.4f}, Train Acc: {train_epoch_accuracy:.2f},Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_accuracy:.2f},time : {epoch_end-epoch_start:.2f}\")\n    torch.save({'history':history},'Master_his.pth')\n    if val_epoch_accuracy > best_acc:\n        best_acc = val_epoch_accuracy\n        best_model_wts = copy.deepcopy(model.state_dict())\n       \n        best_epoch=epoch\n        torch.save({\n            'epoch': epoch+1,\n            'model_state_dict': best_model_wts,\n            'loss': criterion,\n            'history':history,\n            'best_epoch': best_epoch+1,          \n    \n            }, 'Master.pth')    \n  ","metadata":{}},{"cell_type":"code","source":"import time as time\nhistory=[]\nbest_model_wts = copy.deepcopy(model.state_dict())\n#best_optimizer_state = copy.deepcopy(optimizer.state_dict())\nbest_acc = 0.0\nepochs=50\n\nfor epoch in range(epochs):\n    epoch_start = time.time()\n    print('Epoch-{0}/{1} lr: {2}'.format(epoch+1,epochs ,optimizer.param_groups[0]['lr']))\n    \n    train_epoch_loss, train_epoch_accuracy = fit(model,train_dataloader,optimizer,scheduler,criterion)\n    val_epoch_loss, val_epoch_accuracy = validate(model,valid_dataloader,optimizer,criterion)\n    \n    epoch_end = time.time()\n    history.append([epoch+1,train_epoch_loss, train_epoch_accuracy, val_epoch_loss, val_epoch_accuracy,(epoch_end-epoch_start)])\n    print(f\"Train Loss: {train_epoch_loss:.4f}, Train Acc: {train_epoch_accuracy:.2f},Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_accuracy:.2f},time : {epoch_end-epoch_start:.2f}\")\n    torch.save({'history':history},'eft_his_tiny.pth')\n    if val_epoch_accuracy > best_acc:\n        best_acc = val_epoch_accuracy\n        best_model_wts = copy.deepcopy(model.state_dict())\n       \n        best_epoch=epoch\n        torch.save({\n            'epoch': epoch+1,\n            'model_state_dict': best_model_wts,\n            'loss': criterion,\n            'history':history,\n            'best_epoch': best_epoch+1,          \n    \n            }, 'eft_tiny.pth')    \n  ","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:08:27.143182Z","iopub.execute_input":"2023-07-17T09:08:27.143644Z","iopub.status.idle":"2023-07-17T10:19:27.724993Z","shell.execute_reply.started":"2023-07-17T09:08:27.143608Z","shell.execute_reply":"2023-07-17T10:19:27.723377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}