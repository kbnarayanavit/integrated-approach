{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2e16ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import albumentations\n",
    "import albumentations.pytorch \n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "from barbar import Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ace1ad55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "719caf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    torch.backends.cudnn.benchmark=True\n",
    "    torch.backends.cudnn.deterministic=False  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a44053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_pure = '/kaggle/input/breast-256/gcn_256/Train_gcn/*'\n",
    "val_pure =  'gcn_256/Val_gcn/*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c70ecf6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1557"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "#train_files = glob.glob(train_pure)\n",
    "val_files = glob.glob(val_pure)\n",
    "len(val_files)#6229"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5dae5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gcn_256/Val_gcn/SOB_M_PC-15-190EF-200-001.png'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77041760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'200'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=val_files[0]\n",
    "x.split('-')[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a45dd613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373 440 386 358\n"
     ]
    }
   ],
   "source": [
    "val_40=[]\n",
    "val_100=[]\n",
    "val_200=[]\n",
    "val_400=[]\n",
    "for i in val_files:\n",
    "    parts=i.split('-')\n",
    "    if (parts[-2])== \"40\":\n",
    "        val_40.append(i)\n",
    "    elif (parts[-2])== \"100\":\n",
    "        val_100.append(i)\n",
    "    elif (parts[-2])== \"200\":\n",
    "        val_200.append(i)\n",
    "    elif (parts[-2])== \"400\":\n",
    "        val_400.append(i)\n",
    "print(len(val_40),len(val_100),len(val_200),len(val_400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "147f12b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations\n",
    "import albumentations.pytorch \n",
    "class My_data(Dataset):\n",
    "    def __init__(self, data, transforms=None):\n",
    "        self.image_list = data\n",
    "        self.data_len = len(self.image_list)\n",
    "        self.transforms = transforms\n",
    "        self.eicls = [\"A\", \"F\", \"TA\", \"PT\", \"DC\", \"LC\", \"MC\", \"PC\"]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        current_image_path = self.image_list[index]\n",
    "        im_as_im = cv2.imread(current_image_path)\n",
    "        im_as_im = cv2.cvtColor(im_as_im, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Perform label encoding for multi-label classification\n",
    "        parts = current_image_path.split('_')[-1].split('-')\n",
    "        if parts[2]==\"13412\":\n",
    "            labels =[0,0,0,0,1,1,0,0]\n",
    "        else:\n",
    "            labels = [int(label == parts[0]) for label in self.eicls]       \n",
    "        labels = torch.tensor(labels)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            augmented = self.transforms(image=im_as_im)\n",
    "            im_as_im = augmented['image']\n",
    "\n",
    "        return (im_as_im, labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len             \n",
    " \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9ae8a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = {\n",
    "    'train': albumentations.Compose([\n",
    "    albumentations.Resize(256, 256),     \n",
    "    albumentations.OneOf([\n",
    "                          albumentations.HorizontalFlip(),\n",
    "                          albumentations.RandomRotate90(),\n",
    "                          albumentations.VerticalFlip(),\n",
    "                          albumentations.GaussianBlur(),\n",
    "                          albumentations.NoOp()\n",
    "    ], p=1),\n",
    "    albumentations.Normalize(mean=(0.787, 0.625, 0.765),\n",
    "                       std=(0.105, 0.138, 0.089), p=1),\n",
    "    albumentations.pytorch.transforms.ToTensorV2()]),\n",
    "    \n",
    "    'valid': albumentations.Compose([\n",
    "    albumentations.Resize(256, 256),     \n",
    "    albumentations.Normalize(mean=(0.786, 0.623, 0.766),\n",
    "                       std=(0.105, 0.138, 0.089), p=1),\n",
    "    albumentations.pytorch.transforms.ToTensorV2()]),}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecabceda",
   "metadata": {},
   "source": [
    "valid=My_data(val,transforms=transform['valid'])\n",
    "valid_dataloader=  torch.utils.data.DataLoader(dataset=valid,batch_size=1,shuffle=False,num_workers=4,\n",
    "                                               pin_memory=True )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aebb14c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_40=My_data(val_40,transforms=transform['valid'])\n",
    "valid_dataloader1=  torch.utils.data.DataLoader(dataset=valid_40,batch_size=1,shuffle=False,num_workers=4,\n",
    "                                               pin_memory=True )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e7668bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_100=My_data(val_100,transforms=transform['valid'])\n",
    "valid_dataloader2=  torch.utils.data.DataLoader(dataset=valid_100,batch_size=1,shuffle=False,num_workers=4,\n",
    "                                               pin_memory=True )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0e97bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_200=My_data(val_200,transforms=transform['valid'])\n",
    "valid_dataloader3=  torch.utils.data.DataLoader(dataset=valid_200,batch_size=1,shuffle=False,num_workers=4,\n",
    "                                               pin_memory=True )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44d9734d",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_400=My_data(val_400,transforms=transform['valid'])\n",
    "valid_dataloader4=  torch.utils.data.DataLoader(dataset=valid_400,batch_size=1,shuffle=False,num_workers=4,\n",
    "                                               pin_memory=True )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2759ce81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.1557, 0.9852, 1.7349, 2.1382, 0.2863, 1.6080, 1.2578, 1.7620])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "class_samples = [367, 803, 456, 370, 2763, 492, 629, 449]  # Number of samples in each class\n",
    "total_samples = sum(class_samples)\n",
    "samples=total_samples/len(class_samples)\n",
    "class_weights = [samples / (s + 1e-8) for s in class_samples]\n",
    "class_weights = torch.tensor(class_weights)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6325ae45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, class_weights=None):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        probs = torch.sigmoid(logits)\n",
    "        ce_loss = nn.BCELoss()(probs, labels)\n",
    "        weight = (1 - probs).pow(self.gamma)\n",
    "        loss = ce_loss  # Initialize loss with cross-entropy loss\n",
    "        if self.class_weights is not None:\n",
    "            weight = weight * self.class_weights\n",
    "            loss = loss * weight\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8907f556",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kb/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import timm\n",
    "from timm.models import create_model\n",
    "from timm.data import create_transform\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define device\n",
    "# Define Swin Transformer v2 model\n",
    "\"\"\"model_name = 'swin_base_patch4_window7_224'\n",
    "num_classes = 8\n",
    "model = create_model(\n",
    "    model_name=model_name,\n",
    "    pretrained=True,\n",
    "    num_classes=num_classes,\n",
    "    drop_rate=0.5,\n",
    "    drop_path_rate=0.2,\n",
    "    checkpoint_path=None\n",
    ")\"\"\"\n",
    "model = timm.create_model(\n",
    "    'swinv2_tiny_window8_256.ms_in1k',\n",
    "    pretrained=False,\n",
    "    features_only=False,\n",
    "    num_classes = 8,\n",
    "    drop_path_rate=0.2\n",
    ")\n",
    "class_weights=class_weights.to(device)\n",
    "criterion = FocalLoss(class_weights)\n",
    "optimizer = optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()), \n",
    "    lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.5)\n",
    "checkpoint1 = torch.load('ac98data/eft_tiny.pth')\n",
    "model.load_state_dict(checkpoint1['model_state_dict'])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3eb500b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the function that take model and etc.. and compute val loss and val_accuracy and ypred and y true\n",
    "def validate(model, dataloader, optimizer, criterion):\n",
    "    #print('Validating')\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_running_correct = 0\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.float()\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            thresholds = [0.5, 0.5, 0.5,0.5,0.5,0.5,0.5,0.5]\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_running_loss += loss.item()*inputs.size(0)\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            preds = torch.zeros_like(probs)\n",
    "           \n",
    "            y_pred.extend(preds)\n",
    "            y_true.extend(labels)\n",
    "            \n",
    "            #print(preds,labels)\n",
    "            for i, threshold in enumerate(thresholds):\n",
    "                preds[:, i] = (probs[:, i] >= threshold).float()\n",
    "            val_running_correct += (preds == labels).all(dim=1).float().sum()\n",
    "            \n",
    "        \n",
    "    val_loss = val_running_loss/len(dataloader.dataset)\n",
    "    val_accuracy = 100. * val_running_correct/len(dataloader.dataset)        \n",
    "    return val_loss, val_accuracy,y_pred,y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3557054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_40= 0.9946380697050938 recall_40= 0.994750656167979 F1-measure_40= 0.996022681151058 precision_40= 0.9973930623536923\n",
      "0.9946380697050938 & 0.994750656167979 & 0.996022681151058 & 0.9973930623536923\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,recall_score,f1_score,precision_score,matthews_corrcoef,accuracy_score\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "val_loss1, val_accuracy1,y_pred1,y_true1 = validate(model,valid_dataloader1, optimizer, criterion)\n",
    "#converting cuda list to cpu list and subsequently converting numpy\n",
    "#to work with sklearn.matrics\n",
    "y_pred1 = [tensor.cpu().numpy() for tensor in y_pred1]\n",
    "y_true1=  [tensor.cpu().numpy() for tensor in y_true1]\n",
    "#y_pred= torch.tensor(y_pred, device = 'cpu').detach().numpy() \n",
    "#y_true= torch.tensor(y_true, device = 'cpu').detach().numpy() \n",
    "accuracy =accuracy_score (y_true1, y_pred1)       \n",
    "recall=recall_score(y_true1, y_pred1, average='weighted')\n",
    "f1=f1_score(y_true1, y_pred1, average='weighted')\n",
    "precision=precision_score(y_true1, y_pred1, labels=None, pos_label=1, average='weighted')\n",
    "#mcc=matthews_corrcoef(y_true1, y_pred1, sample_weight=None)  \n",
    "print(\"accuracy_40=\",accuracy ,\"recall_40=\",recall,\"F1-measure_40=\",f1,\"precision_40=\" ,precision)\n",
    "print(accuracy , \"&\" ,recall,  \"&\" ,f1  ,\"&\" ,precision)\n",
    "#print(\"accuracy=\",accuracy ,\"recall=\",recall,\"F1-measure=\",f1,\"precision=\" ,precision,\"MCC=\",mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c3d3b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000        20\n",
      "           1      1.000     1.000     1.000        59\n",
      "           2      1.000     1.000     1.000        29\n",
      "           3      1.000     1.000     1.000        17\n",
      "           4      0.993     1.000     0.997       147\n",
      "           5      1.000     0.973     0.986        37\n",
      "           6      1.000     1.000     1.000        47\n",
      "           7      1.000     0.960     0.980        25\n",
      "\n",
      "   micro avg      0.997     0.995     0.996       381\n",
      "   macro avg      0.999     0.992     0.995       381\n",
      "weighted avg      0.997     0.995     0.996       381\n",
      " samples avg      0.997     0.996     0.996       381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true1, y_pred1, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26ec4be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_100= 0.9863636363636363 recall_100= 0.9865168539325843 F1-measure_100= 0.985565744665851 precision_100= 0.984940923480868\n",
      "0.9863636363636363 & 0.9865168539325843 & 0.985565744665851 & 0.984940923480868\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,recall_score,f1_score,precision_score,matthews_corrcoef,accuracy_score\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "val_loss2, val_accuracy2,y_pred2,y_true2 = validate(model,valid_dataloader2, optimizer, criterion)\n",
    "#converting cuda list to cpu list and subsequently converting numpy\n",
    "#to work with sklearn.matrics\n",
    "y_pred2 = [tensor.cpu().numpy() for tensor in y_pred2]\n",
    "y_true2=  [tensor.cpu().numpy() for tensor in y_true2]\n",
    "#y_pred= torch.tensor(y_pred, device = 'cpu').detach().numpy() \n",
    "#y_true= torch.tensor(y_true, device = 'cpu').detach().numpy() \n",
    "accuracy =accuracy_score (y_true2, y_pred2)       \n",
    "recall=recall_score(y_true2, y_pred2, average='weighted')\n",
    "f1=f1_score(y_true2, y_pred2, average='weighted')\n",
    "precision=precision_score(y_true2, y_pred2, labels=None, pos_label=1, average='weighted')\n",
    "#mcc=matthews_corrcoef(y_true1, y_pred1, sample_weight=None)  \n",
    "print(\"accuracy_100=\",accuracy ,\"recall_100=\",recall,\"F1-measure_100=\",f1,\"precision_100=\" ,precision)\n",
    "#print(\"accuracy=\",accuracy ,\"recall=\",recall,\"F1-measure=\",f1,\"precision=\" ,precision,\"MCC=\",mcc)\n",
    "print(accuracy , \"&\" ,recall,  \"&\" ,f1  ,\"&\" ,precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0dc490d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000        22\n",
      "           1      0.984     1.000     0.992        61\n",
      "           2      1.000     1.000     1.000        27\n",
      "           3      1.000     0.952     0.976        21\n",
      "           4      0.995     0.985     0.990       200\n",
      "           5      0.902     0.974     0.937        38\n",
      "           6      0.979     0.979     0.979        47\n",
      "           7      1.000     1.000     1.000        29\n",
      "\n",
      "   micro avg      0.984     0.987     0.985       445\n",
      "   macro avg      0.982     0.986     0.984       445\n",
      "weighted avg      0.985     0.987     0.986       445\n",
      " samples avg      0.986     0.986     0.986       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true2, y_pred2, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d9dd9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_200= 0.9766839378238342 recall_200= 0.9770992366412213 F1-measure_200= 0.9771231241250357 precision_200= 0.9778944211524738\n",
      "0.9766839378238342 & 0.9770992366412213 & 0.9771231241250357 & 0.9778944211524738\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,recall_score,f1_score,precision_score,matthews_corrcoef,accuracy_score\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "val_loss3, val_accuracy3,y_pred3,y_true3 = validate(model,valid_dataloader3, optimizer, criterion)\n",
    "#converting cuda list to cpu list and subsequently converting numpy\n",
    "#to work with sklearn.matrics\n",
    "y_pred3 = [tensor.cpu().numpy() for tensor in y_pred3]\n",
    "y_true3=  [tensor.cpu().numpy() for tensor in y_true3]\n",
    "#y_pred= torch.tensor(y_pred, device = 'cpu').detach().numpy() \n",
    "#y_true= torch.tensor(y_true, device = 'cpu').detach().numpy() \n",
    "accuracy =accuracy_score (y_true3, y_pred3)       \n",
    "recall=recall_score(y_true3, y_pred3, average='weighted')\n",
    "f1=f1_score(y_true3, y_pred3, average='weighted')\n",
    "precision=precision_score(y_true3, y_pred3, labels=None, pos_label=1, average='weighted')\n",
    "#mcc=matthews_corrcoef(y_true1, y_pred1, sample_weight=None)  \n",
    "print(\"accuracy_200=\",accuracy ,\"recall_200=\",recall,\"F1-measure_200=\",f1,\"precision_200=\" ,precision)\n",
    "#print(\"accuracy=\",accuracy ,\"recall=\",recall,\"F1-measure=\",f1,\"precision=\" ,precision,\"MCC=\",mcc)\n",
    "print(accuracy , \"&\" ,recall,  \"&\" ,f1  ,\"&\" ,precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abbab32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000        16\n",
      "           1      0.957     1.000     0.978        45\n",
      "           2      1.000     1.000     1.000        27\n",
      "           3      1.000     0.917     0.957        24\n",
      "           4      0.994     0.972     0.983       181\n",
      "           5      0.941     0.941     0.941        34\n",
      "           6      0.929     1.000     0.963        39\n",
      "           7      0.964     1.000     0.982        27\n",
      "\n",
      "   micro avg      0.977     0.977     0.977       393\n",
      "   macro avg      0.973     0.979     0.975       393\n",
      "weighted avg      0.978     0.977     0.977       393\n",
      " samples avg      0.977     0.977     0.977       393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true3, y_pred3, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2c71294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_400= 0.9720670391061452 recall_400= 0.9778393351800554 F1-measure_400= 0.9749580835916278 precision_400= 0.9727688890477291\n",
      "0.9720670391061452 & 0.9778393351800554 & 0.9749580835916278 & 0.9727688890477291\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,recall_score,f1_score,precision_score,matthews_corrcoef,accuracy_score\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "val_loss4, val_accuracy4,y_pred4,y_true4 = validate(model,valid_dataloader4, optimizer, criterion)\n",
    "#converting cuda list to cpu list and subsequently converting numpy\n",
    "#to work with sklearn.matrics\n",
    "y_pred4 = [tensor.cpu().numpy() for tensor in y_pred4]\n",
    "y_true4=  [tensor.cpu().numpy() for tensor in y_true4]\n",
    "#y_pred= torch.tensor(y_pred, device = 'cpu').detach().numpy() \n",
    "#y_true= torch.tensor(y_true, device = 'cpu').detach().numpy() \n",
    "accuracy =accuracy_score (y_true4, y_pred4)       \n",
    "recall=recall_score(y_true4, y_pred4, average='weighted')\n",
    "f1=f1_score(y_true4, y_pred4, average='weighted')\n",
    "precision=precision_score(y_true4, y_pred4, labels=None, pos_label=1, average='weighted')\n",
    "#mcc=matthews_corrcoef(y_true1, y_pred1, sample_weight=None)  \n",
    "print(\"accuracy_400=\",accuracy ,\"recall_400=\",recall,\"F1-measure_400=\",f1,\"precision_400=\" ,precision)\n",
    "#print(\"accuracy=\",accuracy ,\"recall=\",recall,\"F1-measure=\",f1,\"precision=\" ,precision,\"MCC=\",mcc)\n",
    "print(accuracy , \"&\" ,recall,  \"&\" ,f1  ,\"&\" ,precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff015254",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true4, y_pred4, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fec3e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "98.64 & 98.65 & 98.56 & 98.49\n",
    "97.67 & 97.71 & 97.71 & 97.79\n",
    "97.21 & 97.78 & 97.50 & 97.28"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
